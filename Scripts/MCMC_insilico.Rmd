---
title: "MCMC example"
author: "Eduardo de Freitas Costa"
date: '`r format(Sys.Date(), "%Y-%m-%d")`'
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: yes
    toc_depth: 3
    toc_float: true
editor_options:
  chunk_output_type: console
---

# Script header

File: `Descriptive.rmd`

Client: 
WBVR project: 
Author: Eduardo de Freitas Costa, Wageningen Bioveterinary Research

Start date: \
R version: `r getRversion()`

Dependencies:

-   Downstream

    -   `Data\hiuwalter_model_insilico.txt`

-   Upstream

    -   `None`

-   Input

        -   `None`.

-   Output

    -   `None`

Peer reviewer(s)

------------------------------------------------------------------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


# Load libraries
```{r, include=FALSE}

#Packages to be used
packages<-c("here","tidyverse","ggplot2","knitr","rmarkdown","runjags")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))


```


#Create an in-silico dataset

Set up 4 populations and 3 tests:

 + The populations have equal sample sizes ~100.
 + The prevalences are 10%/5%/10%/60%.
 + The CT values were generated by random from Normal distributions with cut-off around 35.

```{r}
N <- 400
Populations <- 4
prevalence <- c(0.1,0.05,0.1,0.6)
Group <- sample(1:Populations, N, replace=TRUE)

# We set the Se:
##Se_culture:0.2
##Se_PCR1:0.95
##Se_PCR2:0.985
se1 <- 0.2
se2 <- 0.95
se3 <- 0.985

# We set the Sp:
##Sp_culture:0.89
##Sp_PCR1:0.92
##Sp_PCR2:0.95
sp1 <- 0.89
sp2 <- 0.92
sp3 <- 0.95


# Ensure replicable data:
set.seed(2020-02-18)
# Simulate the true latent state (which is unobserved in real! life):
  true <- rbinom(N, 1, prevalence[Group])
  # Simulate test results for test 1:
  test1 <- rbinom(N, 1, se1*true + (1-sp1)*(1-true))
  # Simulate test results for test 2:
  test2 <- rbinom(N, 1, se2*true + (1-sp2)*(1-true))
  # Simulate test results for test 3:
  test3 <- rbinom(N, 1, se3*true + (1-sp3)*(1-true))
  
simdata <- data.frame(Population=factor(Group), Test1=test1, Test2=test2, Test3=test3)

#Set continuous values to the tests
set.seed(2020-02-18)
simdata$CT_T2=rnorm(400,simdata$Test2+35,sd=2)
simdata$CT_T3=rnorm(400,simdata$Test2+35,sd=2)


```

# Run the MCMC model

Running the Bayesian MCMC simulation on a hui-walter template with 2 chains, 10000 samples, burnin=1500 and thin=2. 

 + This model assumes `non-informative` priors.
 + This model also assumes that the tests are independent from each other.
 
```{r}


if (file.exists(here("Data","huiwalter_model_insilico.txt"))){
results <- run.jags(here("Data","huiwalter_model_insilico.txt"),
                    burnin = 1500,
                    sample = 10000,
                    n.chains = 2,
                    thin = 2)
  
} else{
template_huiwalter(simdata,outfile=here("Data","huiwalter_model_insilico.txt"), covariance=FALSE,
                   se_priors = "dbeta(1,1)",
                    sp_priors = "dbeta(1,1)")

results <- run.jags(here("Data","huiwalter_model_insilico.txt"),
                    burnin = 1500,
                    sample = 10000,
                    n.chains = 2,
                    thin = 2)
  
  
}

```

# Model's result and diagnostic

We can see that the theoretical values used to generate the `in-silico` dataset is contained within the 95% credible interval.

```{r}
summary(results)


data1=cbind.data.frame(parameter=c("prev[1]",
                                  "prev[2]",
                                  "prev[3]",
                                  "prev[4]",
                                  "se[1]",
                                  "se[2]",
                                  "se[3]",
                                  "sp[1]",
                                  "sp[2]",
                                  "sp[3]"),
                      value=c(prevalence,se1,se2,se3,sp1,sp2,sp3))

combine.mcmc(results)%>%
  as_tibble()%>%
  gather(key="parameter",value="value")%>%
  dplyr::filter(!str_detect(parameter, "ppp"))%>%
  ggplot(aes(x=parameter,y=value))+
  geom_violin()+
  geom_point(data=data1,aes(x=parameter,y=value))+
  theme_minimal()

#plot(results, vars = c("se", "sp", "prev"),density=F)



```

# Implement cut-offs for continous tests

```{r}

## PPP values are calculated in JAGS, so need to be extracted from 10,000 (thinned) iterations:
ppp_values <- combine.mcmc(results, return.samples=10000, vars="ppp")

## Mean PPP values (n = 28) based on 1000 iterations
(mean_ppp <- apply(ppp_values, 2,  mean))

## Map the 28 mean PPVs to all the observations (n = 233) in the df1 dataset
simdata %>%
  mutate(	testcombo = interaction(Test1, Test2), 
  			colname = str_c("ppp[", as.numeric(testcombo), ",", as.numeric(Population), "]"), 
  			colindex = match(colname, names(mean_ppp)), 
  			mean_ppp = mean_ppp[colindex]
  		) ->test_data

```

# Plot the results of the cut-off investigation

```{r}
possible_pp <- tibble(LT = c(0, sort(unique(test_data$CT_T3)))) %>%
  mutate(UT = lead(LT, default=max(test_data$CT_T3)+1), MT = (LT+UT)/2, IT = 1:n()) 

cutoff_fun <- function(iter){
  test_data %>%
    select(CT_T3, colindex) %>%
    mutate(PPP = ppp_values[iter,colindex]) %>%
    expand_grid(possible_pp) %>%
    group_by(IT, LT, MT, UT) %>%
    summarise(	Iteration = iter, 
    			SeNum = sum(PPP[CT_T3 >= MT]), SeDen = sum(PPP),
    			SpNum = sum(1-PPP[CT_T3 < MT]), SpDen = sum(1-PPP), 
    			.groups='drop')
}
library(pbapply)
cutoff_evaluation <- pblapply(seq_len(coda::niter(ppp_values)), cutoff_fun) %>%
	bind_rows() %>%
	mutate(
		Sensitivity = SeNum / SeDen,
		Specificity = SpNum / SpDen,
		SeCI = rbeta(n(), SeNum+1, SeDen-SeNum+1),
		SpCI = rbeta(n(), SpNum+1, SpDen-SpNum+1)
	 )


## Create a plot of sensitivity, specificity and sum vs PP value:
	 
getci <- function(x, upper=TRUE) coda::HPDinterval(coda::as.mcmc(x))[,as.numeric(upper)+1]
plotdata <- cutoff_evaluation %>%
	 group_by(IT, LT, MT, UT) %>%
	 summarise(
	 	Se_Mean = mean(SeNum / SeDen),
	 	Se_LCI = getci(SeCI, FALSE),
	 	Se_UCI = getci(SeCI, TRUE),
	 	Sp_Mean = mean(SpNum / SpDen),
	 	Sp_LCI = getci(SpCI, FALSE),
	 	Sp_UCI = getci(SpCI, TRUE),
	 	.groups = "drop"
	 ) %>%
	 mutate(
	 	Sum_Mean = Se_Mean + Sp_Mean,
	 	Sum_LCI = Se_LCI + Sp_LCI,
	 	Sum_UCI = Se_UCI + Sp_UCI
	 ) %>%
	 pivot_longer(
	 	cols = Se_Mean:Sum_UCI,
	 	names_to = c("Parameter", "Estimate"),
	 	names_pattern = "(.*)_(.*)",
	 	values_to = "Value"
	 ) %>%
	 mutate(Value = Value * 100) %>%
	 pivot_wider(
	 	names_from = Estimate, values_from = Value
	 ) %>%
	 pivot_longer(
	 	cols = LT:UT,
	 	names_to = "Boundary",
	 	values_to = "PP"
	 ) %>%
	 mutate(Parameter = factor(Parameter, levels=c("Sum", "Se", "Sp"), labels = c("Sensitivity + Specificity", "Sensitivity", "Specificity")))

optimal <- plotdata %>%
	filter(Parameter == "Sensitivity + Specificity", Boundary == "MT") %>%
	arrange(desc(Mean)) %>%
	slice(1) %>%
	pull(PP)
#optimal

round(optimal, 1)

# Beware floating point arithmetic!
#print(optimal, digits=20)
(optimal <- round(optimal + 1e-6, 1))

ggplot(plotdata) +
	aes(x = PP, y = Mean, ymin = LCI, ymax = UCI) +
	geom_ribbon(alpha=0.25) +
	geom_line() +
	geom_vline(xintercept = optimal, lty="dashed") +
	facet_wrap( ~ Parameter, scales="free_y", ncol=1) +
	xlab("CT value") +
	ylab(NULL) +
  xlim(30,40)+
#	scale_x_continuous(breaks = seq(20,40,by=15))+
  theme_minimal()+
  ggtitle(paste0("Se+Sp optimization, "," Cut-off: ",optimal))
  #annotate(geom="text",x=31,y=75,label=)


plotdata%>%
  dplyr::filter(Parameter %in% c("Sensitivity","Specificity"))%>%
ggplot(aes(x=PP, y=Mean, ymin=LCI, ymax=UCI, col=Parameter, fill=Parameter))+
  geom_ribbon(alpha=0.25) +
	geom_line()+
  geom_vline(xintercept = optimal, color = "red")+
  geom_vline(xintercept = 35, color = "black")+
  theme_minimal()+
  	xlab("CT value") +
  ggtitle("Optimum vs used cut-off")


## Create a ROC curve:
roc_ci <- cutoff_evaluation %>%
	mutate(Se = as.integer(round(SeCI*100)), Sp = as.integer(round(SpCI*100))) %>%
	group_by(Sp) %>%
	summarise(LCI = getci(Se, FALSE), UCI = getci(Se, TRUE), Se = mean(Se)) %>%
	arrange(Se, 1-Sp)
roc_mean <- cutoff_evaluation %>%
	group_by(IT,LT,MT,UT) %>%
	summarise(Se = mean(SeNum/SeDen)*100, Sp = mean(SpNum/SpDen)*100, .groups='drop')
roc_opt <- plotdata %>%
	filter(abs(round(PP , 1) - optimal) ==0, Parameter %in% c("Sensitivity","Specificity")) %>%
	select(Parameter, Mean) %>%
  group_by(Parameter)%>%
  summarise(Mean=mean(Mean))%>%
	pivot_wider(names_from = Parameter, values_from = Mean)

ggplot() + 
	geom_ribbon(aes(x=100-Sp, y=Se, ymin=LCI, ymax=UCI), roc_ci, alpha = 0.25) +
	geom_line(aes(x=100-Sp, y=Se), roc_mean) +
	geom_point(aes(x=100-Specificity, y=Sensitivity), roc_opt, pch = 8, col="black") +
	ylab('Sensitivity') + xlab('1 - Specificity') +
	geom_abline(slope=1, intercept=0, lty='dashed') +
	ylim(0,100)+
  theme_minimal()+
  ggtitle(paste0("ROC courve ","Se= ", round(roc_opt[1],2)," ", "Sp= ",round(roc_opt[2],2)))+
  annotate(geom="text", x=20,y=75,
           label=paste0("AUC= ",
                        integrate(approxfun(1-roc_mean$Sp/100, roc_mean$Se/100), 0, 1,subdivisions = 1000L)[1])
             )

# Calculate AUC:
#integrate(approxfun(1-roc_mean$Sp/100, roc_mean$Se/100), 0, 1,subdivisions = 1000L)

```

